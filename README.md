# ğŸ  Property Finder - Production Ready

A modern property finder application with automated daily scraping, built for Railway deployment.

## ğŸŒŸ Features

- **ğŸ” Property Search**: Search houses and businesses with advanced filters
- **ğŸ“Š Data Visualization**: Interactive maps and charts
- **ğŸ•·ï¸ Automated Scraping**: Daily property data collection via GitHub Actions  
- **ğŸ“ CSV Import/Export**: Bulk data management
- **ğŸŒ RESTful API**: Full-featured backend API
- **ğŸ“± Modern UI**: Responsive React frontend

## ğŸš€ Quick Deploy to Railway

### 1. Upload to GitHub
- Create new repository on GitHub
- Upload all files from this directory
- Commit with message: "Initial commit - Property finder app"

### 2. Deploy to Railway
- Go to [railway.app](https://railway.app)
- Connect GitHub account
- "New Project" â†’ "Deploy from GitHub repo"
- Select your repository

### 3. Add Database
- In Railway: "New" â†’ "Database" â†’ "PostgreSQL"
- Railway auto-generates `DATABASE_URL`

### 4. Set Environment Variables
```env
NODE_ENV=production
SCRAPER_API_KEY=your-secure-key-here
SCRAPER_PATH=../scraper
GEOCODING_API_KEY=your-google-maps-api-key
```

### 5. Configure GitHub Secrets
For automated scraping:
```env
SCRAPER_API_KEY=your-secure-key-here
API_BASE_URL=https://your-app.railway.app
```

## ğŸ“ Project Structure

```
property-finder/
â”œâ”€â”€ property-finder-api/     # Node.js API server
â”œâ”€â”€ property-finder-ui/      # React frontend
â”œâ”€â”€ scraper/                 # Python web scraping
â”œâ”€â”€ .github/workflows/       # GitHub Actions automation
â”œâ”€â”€ Dockerfile              # Railway deployment
â”œâ”€â”€ railway.toml            # Railway configuration
â””â”€â”€ README.md               # This file
```

## ğŸ”§ API Endpoints

- `GET /health` - System health check
- `GET /api/search` - Search properties
- `POST /api/house` - Add house record
- `POST /api/business` - Add business record
- `POST /api/scraper/start` - Trigger scraping
- `GET /api/scraper/status` - Check scraping status

## ğŸ•·ï¸ Automated Scraping

- **Schedule**: Daily at 2 AM UTC
- **Trigger**: GitHub Actions workflow
- **Security**: API key authentication
- **Monitoring**: Status and logs via API

## ğŸ§ª Testing

After deployment, verify with:
```bash
python verify_deployment.py https://your-app.railway.app your-api-key
```

## ğŸ“š Documentation

- `RAILWAY_DEPLOY.md` - Detailed deployment guide
- `DEPLOY_STEPS.md` - Step-by-step instructions  
- `SCRAPING_SETUP.md` - Scraping configuration
- `scraper/DAILY_SETUP_GUIDE.md` - Scraper details

## ğŸ”’ Security

- Environment variables for secrets
- API key authentication for scraping
- Rate limiting on endpoints
- CORS configuration

## ğŸŒ Live App

Once deployed, your app will be available at:
`https://your-app-name.railway.app`

## ğŸ¯ Next Steps

1. **Deploy**: Follow the deployment guide
2. **Configure**: Set environment variables
3. **Test**: Run verification script
4. **Monitor**: Check daily scraping automation
5. **Use**: Start adding/searching properties!

---

Built with â¤ï¸ using Node.js, React, Python, and Railway
